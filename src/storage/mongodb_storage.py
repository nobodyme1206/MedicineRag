#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MongoDBå…ƒæ•°æ®å­˜å‚¨æ¨¡å—
ç”¨äºå­˜å‚¨æ–‡æ¡£å…ƒæ•°æ®ã€æŸ¥è¯¢æ—¥å¿—ã€ç³»ç»Ÿç»Ÿè®¡ç­‰
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
from typing import List, Dict, Optional
import pandas as pd
from datetime import datetime
from config.config import *
from src.utils.logger import setup_logger

logger = setup_logger("mongodb_storage", LOGS_DIR / "mongodb_storage.log")


class MongoDBStorage:
    """MongoDBæ–‡æ¡£æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(
        self,
        host: str = "localhost",
        port: int = 27017,
        database: str = "medical_rag"
    ):
        """
        åˆå§‹åŒ–MongoDBè¿æ¥
        
        Args:
            host: MongoDBä¸»æœºåœ°å€
            port: ç«¯å£
            database: æ•°æ®åº“åç§°
        """
        try:
            self.client = MongoClient(
                host=host,
                port=port,
                serverSelectionTimeoutMS=5000
            )
            # æµ‹è¯•è¿æ¥
            self.client.admin.command('ping')
            
            self.db = self.client[database]
            logger.info(f"âœ… è¿æ¥MongoDBæˆåŠŸ: {host}:{port}/{database}")
            
        except ConnectionFailure as e:
            logger.error(f"âŒ è¿æ¥MongoDBå¤±è´¥: {e}")
            raise
    
    def save_chunks_metadata(self, chunks: List[Dict], collection_name: str = "chunks_metadata"):
        """
        ä¿å­˜æ–‡æ¡£chunkså…ƒæ•°æ®åˆ°MongoDB
        
        Args:
            chunks: æ–‡æ¡£chunksåˆ—è¡¨
            collection_name: é›†åˆåç§°
            
        Returns:
            æ’å…¥çš„æ–‡æ¡£æ•°é‡
        """
        collection = self.db[collection_name]
        
        logger.info(f"å¼€å§‹ä¿å­˜ {len(chunks)} ä¸ªchunkså…ƒæ•°æ®...")
        
        # æ·»åŠ æ—¶é—´æˆ³
        for chunk in chunks:
            chunk['created_at'] = datetime.now()
            chunk['updated_at'] = datetime.now()
        
        # æ‰¹é‡æ’å…¥
        if chunks:
            result = collection.insert_many(chunks)
            logger.info(f"âœ… ä¿å­˜æˆåŠŸ: {len(result.inserted_ids)} ä¸ªæ–‡æ¡£")
            return len(result.inserted_ids)
        
        return 0
    
    def query_chunks_by_category(
        self,
        category: str,
        limit: int = 100,
        collection_name: str = "chunks_metadata"
    ) -> List[Dict]:
        """
        æŒ‰ç±»åˆ«æŸ¥è¯¢chunkså…ƒæ•°æ®
        
        Args:
            category: ç–¾ç—…ç±»åˆ«
            limit: è¿”å›æ•°é‡é™åˆ¶
            collection_name: é›†åˆåç§°
            
        Returns:
            ç¬¦åˆæ¡ä»¶çš„æ–‡æ¡£åˆ—è¡¨
        """
        collection = self.db[collection_name]
        
        logger.info(f"æŸ¥è¯¢ç±»åˆ«: {category}, é™åˆ¶: {limit}")
        
        results = list(collection.find(
            {"category": category},
            {"_id": 0}  # æ’é™¤_idå­—æ®µ
        ).limit(limit))
        
        logger.info(f"âœ… æŸ¥è¯¢åˆ° {len(results)} æ¡ç»“æœ")
        
        return results
    
    def log_query(
        self,
        query_text: str,
        results: List[Dict],
        metrics: Dict,
        collection_name: str = "query_logs"
    ):
        """
        è®°å½•æŸ¥è¯¢æ—¥å¿—
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            results: æ£€ç´¢ç»“æœ
            metrics: æ€§èƒ½æŒ‡æ ‡ (å¬å›ç‡ã€å»¶è¿Ÿç­‰)
            collection_name: é›†åˆåç§°
        """
        collection = self.db[collection_name]
        
        log_entry = {
            'timestamp': datetime.now(),
            'query': query_text,
            'num_results': len(results),
            'metrics': metrics,
            'result_ids': [r.get('id', '') for r in results[:10]]  # åªè®°å½•å‰10ä¸ª
        }
        
        collection.insert_one(log_entry)
        logger.debug(f"æŸ¥è¯¢æ—¥å¿—å·²è®°å½•: {query_text[:50]}...")
    
    def get_query_statistics(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        collection_name: str = "query_logs"
    ) -> Dict:
        """
        è·å–æŸ¥è¯¢ç»Ÿè®¡æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            collection_name: é›†åˆåç§°
            
        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        collection = self.db[collection_name]
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {}
        if start_date or end_date:
            query['timestamp'] = {}
            if start_date:
                query['timestamp']['$gte'] = start_date
            if end_date:
                query['timestamp']['$lte'] = end_date
        
        # èšåˆç»Ÿè®¡
        pipeline = [
            {'$match': query},
            {'$group': {
                '_id': None,
                'total_queries': {'$sum': 1},
                'avg_results': {'$avg': '$num_results'},
                'avg_recall': {'$avg': '$metrics.recall'},
                'avg_latency': {'$avg': '$metrics.latency_ms'}
            }}
        ]
        
        result = list(collection.aggregate(pipeline))
        
        if result:
            stats = result[0]
            stats.pop('_id')
            logger.info(f"æŸ¥è¯¢ç»Ÿè®¡: {stats}")
            return stats
        
        return {}
    
    def save_evaluation_results(
        self,
        results: Dict,
        collection_name: str = "evaluation_results"
    ):
        """
        ä¿å­˜è¯„ä¼°ç»“æœ
        
        Args:
            results: è¯„ä¼°ç»“æœå­—å…¸
            collection_name: é›†åˆåç§°
        """
        collection = self.db[collection_name]
        
        results['timestamp'] = datetime.now()
        
        collection.insert_one(results)
        logger.info(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜")
    
    def get_latest_evaluation(self, collection_name: str = "evaluation_results") -> Optional[Dict]:
        """
        è·å–æœ€æ–°çš„è¯„ä¼°ç»“æœ
        
        Args:
            collection_name: é›†åˆåç§°
            
        Returns:
            æœ€æ–°è¯„ä¼°ç»“æœ
        """
        collection = self.db[collection_name]
        
        result = collection.find_one(
            {},
            {"_id": 0},
            sort=[("timestamp", -1)]
        )
        
        if result:
            logger.info(f"è·å–æœ€æ–°è¯„ä¼°: {result.get('timestamp')}")
        
        return result
    
    def create_indexes(self):
        """åˆ›å»ºå¸¸ç”¨ç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""
        
        # chunks_metadataç´¢å¼•
        self.db.chunks_metadata.create_index("category")
        self.db.chunks_metadata.create_index("created_at")
        
        # query_logsç´¢å¼•
        self.db.query_logs.create_index("timestamp")
        self.db.query_logs.create_index([("timestamp", -1)])  # é™åºç´¢å¼•
        
        # evaluation_resultsç´¢å¼•
        self.db.evaluation_results.create_index([("timestamp", -1)])
        
        logger.info("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def get_collection_stats(self, collection_name: str) -> Dict:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
        
        Args:
            collection_name: é›†åˆåç§°
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        collection = self.db[collection_name]
        
        stats = {
            'count': collection.count_documents({}),
            'indexes': [idx['name'] for idx in collection.list_indexes()],
            'size_mb': self.db.command("collStats", collection_name).get('size', 0) / (1024**2)
        }
        
        return stats
    
    def close(self):
        """å…³é—­MongoDBè¿æ¥"""
        self.client.close()
        logger.info("MongoDBè¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    # æµ‹è¯•MongoDBå­˜å‚¨
    print("=" * 70)
    print("ğŸ“Š MongoDBå­˜å‚¨æµ‹è¯•")
    print("=" * 70)
    
    print("\nâš ï¸ è¯·å…ˆå¯åŠ¨MongoDBæœåŠ¡:")
    print("docker run -d -p 27017:27017 --name mongodb \\")
    print("  -e MONGO_INITDB_ROOT_USERNAME=admin \\")
    print("  -e MONGO_INITDB_ROOT_PASSWORD=admin123 \\")
    print("  mongo:latest")
    
    try:
        storage = MongoDBStorage()
        
        # åˆ›å»ºç´¢å¼•
        print("\nğŸ“‘ åˆ›å»ºç´¢å¼•...")
        storage.create_indexes()
        
        # æµ‹è¯•ä¿å­˜å…ƒæ•°æ®
        test_chunks = [
            {
                'id': 'test_001',
                'text': 'Type 2 diabetes is a chronic condition...',
                'category': 'diabetes',
                'pmid': '12345678'
            },
            {
                'id': 'test_002',
                'text': 'Cardiovascular disease affects millions...',
                'category': 'cardiovascular',
                'pmid': '87654321'
            }
        ]
        
        print(f"\nğŸ’¾ ä¿å­˜æµ‹è¯•æ•°æ®: {len(test_chunks)} æ¡")
        storage.save_chunks_metadata(test_chunks, "test_chunks")
        
        # æµ‹è¯•æŸ¥è¯¢
        print("\nğŸ” æŒ‰ç±»åˆ«æŸ¥è¯¢:")
        results = storage.query_chunks_by_category("diabetes", collection_name="test_chunks")
        for r in results:
            print(f"  {r['id']}: {r['text'][:50]}...")
        
        # æµ‹è¯•æŸ¥è¯¢æ—¥å¿—
        print("\nğŸ“ è®°å½•æŸ¥è¯¢æ—¥å¿—:")
        storage.log_query(
            "What is diabetes?",
            results,
            {'recall': 0.85, 'latency_ms': 120.5}
        )
        
        # è·å–ç»Ÿè®¡
        print("\nğŸ“Š æŸ¥è¯¢ç»Ÿè®¡:")
        stats = storage.get_query_statistics()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # è·å–é›†åˆç»Ÿè®¡
        print("\nğŸ“ˆ é›†åˆç»Ÿè®¡:")
        for coll in ['test_chunks', 'query_logs']:
            coll_stats = storage.get_collection_stats(coll)
            print(f"  {coll}:")
            for key, value in coll_stats.items():
                print(f"    {key}: {value}")
        
        storage.close()
        
        print("\nâœ… MongoDBå­˜å‚¨æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        print("æç¤º: è¯·ç¡®ä¿MongoDBæœåŠ¡å·²å¯åŠ¨")
